{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMml88t0tL3Vu8JDNAGQj9y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a-kanaan/dnn-anki/blob/main/MLP_regression_falls_within_a_given_range.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What activation function to use in MLP for regression when you want to gaurantee predictions will fall within a given range of values "
      ],
      "metadata": {
        "id": "vsRIrnslpjHi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDtjZYnjnsA6",
        "outputId": "302d8a61-6d06-47f6-9474-07de44eed686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(array([0.5488135 , 0.71518937, 0.60276338]), 94), (array([0.54488318, 0.4236548 , 0.64589411]), 91), (array([0.43758721, 0.891773  , 0.96366276]), 43), (array([0.38344152, 0.79172504, 0.52889492]), 63), (array([0.56804456, 0.92559664, 0.07103606]), 31), (array([0.0871293 , 0.0202184 , 0.83261985]), 20), (array([0.77815675, 0.87001215, 0.97861834]), 70), (array([0.79915856, 0.46147936, 0.78052918]), 9), (array([0.11827443, 0.63992102, 0.14335329]), 60), (array([0.94466892, 0.52184832, 0.41466194]), 91), (array([0.26455561, 0.77423369, 0.45615033]), 35), (array([0.56843395, 0.0187898 , 0.6176355 ]), 83), (array([0.61209572, 0.616934  , 0.94374808]), 76), (array([0.6818203 , 0.3595079 , 0.43703195]), 18), (array([0.6976312 , 0.06022547, 0.66676672]), 74), (array([0.67063787, 0.21038256, 0.1289263 ]), 98), (array([0.31542835, 0.36371077, 0.57019677]), 97), (array([0.43860151, 0.98837384, 0.10204481]), 43), (array([0.20887676, 0.16130952, 0.65310833]), 3), (array([0.2532916 , 0.46631077, 0.24442559]), 12), (array([0.15896958, 0.11037514, 0.65632959]), 58), (array([0.13818295, 0.19658236, 0.36872517]), 1), (array([0.82099323, 0.09710128, 0.83794491]), 0), (array([0.09609841, 0.97645947, 0.4686512 ]), 39), (array([0.97676109, 0.60484552, 0.73926358]), 24), (array([0.03918779, 0.28280696, 0.12019656]), 58), (array([0.2961402 , 0.11872772, 0.31798318]), 36), (array([0.41426299, 0.0641475 , 0.69247212]), 99), (array([0.56660145, 0.26538949, 0.52324805]), 69), (array([0.09394051, 0.5759465 , 0.9292962 ]), 6), (array([0.31856895, 0.66741038, 0.13179786]), 3), (array([0.7163272 , 0.28940609, 0.18319136]), 98), (array([0.58651293, 0.02010755, 0.82894003]), 40), (array([0.00469548, 0.67781654, 0.27000797]), 60), (array([0.73519402, 0.96218855, 0.24875314]), 33), (array([0.57615733, 0.59204193, 0.57225191]), 28), (array([0.22308163, 0.95274901, 0.44712538]), 68), (array([0.84640867, 0.69947928, 0.29743695]), 26), (array([0.81379782, 0.39650574, 0.8811032 ]), 96), (array([0.58127287, 0.88173536, 0.69253159]), 51), (array([0.72525428, 0.50132438, 0.95608363]), 73), (array([0.6439902 , 0.42385505, 0.60639321]), 53), (array([0.0191932 , 0.30157482, 0.66017354]), 69), (array([0.29007761, 0.61801543, 0.4287687 ]), 33), (array([0.13547406, 0.29828233, 0.56996491]), 7), (array([0.59087276, 0.57432525, 0.65320082]), 94), (array([0.65210327, 0.43141844, 0.8965466 ]), 72), (array([0.36756187, 0.43586493, 0.89192336]), 84), (array([0.80619399, 0.70388858, 0.10022689]), 7), (array([0.91948261, 0.7142413 , 0.99884701]), 67), (array([0.1494483 , 0.86812606, 0.16249293]), 85), (array([0.61555956, 0.12381998, 0.84800823]), 91), (array([0.80731896, 0.56910074, 0.4071833 ]), 67), (array([0.069167  , 0.69742877, 0.45354268]), 84), (array([0.7220556 , 0.86638233, 0.97552151]), 71), (array([0.85580334, 0.01171408, 0.35997806]), 83), (array([0.72999056, 0.17162968, 0.52103661]), 95), (array([0.05433799, 0.19999652, 0.01852179]), 0), (array([0.7936977 , 0.22392469, 0.34535168]), 5), (array([0.92808129, 0.7044144 , 0.03183893]), 91), (array([0.16469416, 0.6214784 , 0.57722859]), 30), (array([0.23789282, 0.934214  , 0.61396596]), 73), (array([0.5356328 , 0.58990998, 0.73012203]), 83), (array([0.311945  , 0.39822106, 0.20984375]), 7), (array([0.18619301, 0.94437239, 0.7395508 ]), 21), (array([0.49045881, 0.22741463, 0.25435648]), 92), (array([0.05802916, 0.43441663, 0.31179588]), 8), (array([0.69634349, 0.37775184, 0.17960368]), 43), (array([0.02467873, 0.06724963, 0.67939277]), 46), (array([0.45369684, 0.53657921, 0.89667129]), 0), (array([0.99033895, 0.21689698, 0.6630782 ]), 51), (array([0.26332238, 0.020651  , 0.75837865]), 38), (array([0.32001715, 0.38346389, 0.58831711]), 89), (array([0.83104846, 0.62898184, 0.87265066]), 74), (array([0.27354203, 0.79804683, 0.18563594]), 98), (array([0.95279166, 0.68748828, 0.21550768]), 87), (array([0.94737059, 0.73085581, 0.25394164]), 96), (array([0.21331198, 0.51820071, 0.02566272]), 83), (array([0.20747008, 0.42468547, 0.37416998]), 26), (array([0.46357542, 0.27762871, 0.58678435]), 78), (array([0.86385561, 0.11753186, 0.51737911]), 32), (array([0.13206811, 0.71685968, 0.3960597 ]), 70), (array([0.56542131, 0.18327984, 0.14484776]), 97), (array([0.48805628, 0.35561274, 0.94043195]), 44), (array([0.76532525, 0.74866362, 0.90371974]), 59), (array([0.08342244, 0.55219247, 0.58447607]), 57), (array([0.96193638, 0.29214753, 0.24082878]), 50), (array([0.10029394, 0.01642963, 0.92952932]), 45), (array([0.66991655, 0.78515291, 0.28173011]), 4), (array([0.58641017, 0.06395527, 0.4856276 ]), 57), (array([0.97749514, 0.87650525, 0.33815895]), 93), (array([0.96157015, 0.23170163, 0.94931882]), 91), (array([0.9413777 , 0.79920259, 0.63044794]), 17), (array([0.87428797, 0.29302028, 0.84894356]), 35), (array([0.61787669, 0.01323686, 0.34723352]), 66), (array([0.14814086, 0.98182939, 0.47837031]), 20), (array([0.49739137, 0.63947252, 0.36858461]), 45), (array([0.13690027, 0.82211773, 0.18984791]), 57), (array([0.51131898, 0.22431703, 0.09784448]), 79), (array([0.86219152, 0.97291949, 0.96083466]), 36)]\n",
            "[47.20868251 49.76175221 49.58493988 44.26191369 47.73658108 51.53124281\n",
            " 46.99461506 49.43899939 52.79462143 41.85982561]\n",
            "training sample:  [0.5488135  0.71518937 0.60276338]\n",
            "predicted value:  [50.40055602]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np \n",
        "from sklearn.neural_network import MLPRegressor \n",
        "\n",
        "# Generate some simulated data \n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 3) # 100 samples with 3 features \n",
        "y = np.random.randint(0, 100, size=100) # Target values in the range [0, 100] \n",
        "\n",
        "print([(_x, _y) for _x, _y in zip(X, y)])\n",
        "\n",
        "# Scale the target values to fall within the range [0, 1] \n",
        "y_scaled = y / 100 #<-----------------HERE\n",
        "\n",
        "# Create an MLP with one hidden layer of 10 neurons \n",
        "mlp = MLPRegressor(hidden_layer_sizes=(10,), activation='logistic', max_iter=1000) \n",
        "\n",
        "# Fit the MLP to the data \n",
        "mlp.fit(X, y_scaled) \n",
        "\n",
        "# Predict on new data \n",
        "X_new = np.random.rand(10, 3) # 10 new samples with 3 features \n",
        "y_pred_scaled = mlp.predict(X_new) \n",
        "\n",
        "# Map the predictions back to the original scale \n",
        "y_pred = y_pred_scaled * 100 \n",
        "print(y_pred) # Predicted values in the range [0, 100] <-----------------HERE\n",
        "\n",
        "print(\"training sample: \", X[0, :])\n",
        "print(\"predicted value: \", mlp.predict([X[0, :]]) * 100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MKTv1WubntyI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}